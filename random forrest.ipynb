{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58e5356-9c79-440d-9565-a2ee44863787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/92/394r745n3cxg7hwft9b6jmt40000gn/T/ipykernel_10763/3393062247.py:19: DtypeWarning: Columns (56,57,58,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Merged_WB_PWT_DEMO.csv\", encoding=\"utf-8-sig\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGI columns: Index(['country', 'year', 'cc', 'ge', 'pv', 'rl', 'rq', 'va'], dtype='object', name='indicator')\n",
      "['country', 'year', 'EG.ELC.ACCS.ZS', 'GC.DOD.TOTL.GD.ZS', 'GC.NLD.TOTL.GD.ZS', 'MS.MIL.XPND.GD.ZS', 'trade_openness', 'NY.ADJ.NNTY.KD.ZG', 'NY.GDP.MKTP.KD.ZG', 'gdp_pc', 'gdp_pc_growth', 'rgdpe', 'rgdpo', 'pop', 'emp', 'avh', 'education', 'ccon', 'cda', 'cgdpe', 'cgdpo', 'cn', 'ck', 'ctfp', 'cwtfp', 'rgdpna', 'rconna', 'rdana', 'rnna', 'rkna', 'rtfpna', 'rwtfpna', 'labsh', 'irr', 'delta', 'xr', 'pl_con', 'pl_da', 'pl_gdpo', 'i_cig', 'i_xm', 'i_xr', 'i_outlier', 'i_irr', 'cor_exp', 'csh_c', 'csh_i', 'csh_g', 'csh_x', 'csh_m', 'csh_r', 'pl_c', 'pl_i', 'pl_g', 'pl_x', 'pl_m', 'pl_n', 'pl_k', 'pop_growth', 'cc', 'ge', 'pv', 'rl', 'rq', 'va']\n",
      "   country  year EG.ELC.ACCS.ZS GC.DOD.TOTL.GD.ZS GC.NLD.TOTL.GD.ZS  \\\n",
      "0  Albania  1980            NaN               NaN               NaN   \n",
      "1  Albania  1981            NaN               NaN               NaN   \n",
      "2  Albania  1982            NaN               NaN               NaN   \n",
      "3  Albania  1983            NaN               NaN               NaN   \n",
      "4  Albania  1984            NaN               NaN               NaN   \n",
      "\n",
      "  MS.MIL.XPND.GD.ZS    trade_openness NY.ADJ.NNTY.KD.ZG  NY.GDP.MKTP.KD.ZG  \\\n",
      "0  6.05202163275818  47.4940925041872               NaN                NaN   \n",
      "1  5.84831705344366  46.1004662837047               NaN   5.74563529228132   \n",
      "2  5.65159574468085  44.8105616083383               NaN   2.94859680118944   \n",
      "3  5.44128198995456  40.4106676033234               NaN   1.10493826195055   \n",
      "4  6.11750454270139  38.1156830212927               NaN  -1.25159664405811   \n",
      "\n",
      "        gdp_pc  ...      pl_m      pl_n      pl_k  pop_growth  cc  ge  pv  rl  \\\n",
      "0  1823.489260  ...  0.303469  0.218719  0.454636    2.015041 NaN NaN NaN NaN   \n",
      "1  1890.021975  ...  0.320215  0.203089  0.370326    2.010553 NaN NaN NaN NaN   \n",
      "2  1905.063527  ...  0.285771  0.203166  0.359275    2.024575 NaN NaN NaN NaN   \n",
      "3  1885.692800  ...  0.306429  0.206717  0.322750    2.045132 NaN NaN NaN NaN   \n",
      "4  1823.323563  ...  0.314529  0.207734  0.295824    2.059391 NaN NaN NaN NaN   \n",
      "\n",
      "   rq  va  \n",
      "0 NaN NaN  \n",
      "1 NaN NaN  \n",
      "2 NaN NaN  \n",
      "3 NaN NaN  \n",
      "4 NaN NaN  \n",
      "\n",
      "[5 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm, linear_model, datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score,\n",
    "                             accuracy_score, roc_auc_score, RocCurveDisplay)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "df = pd.read_csv(\"Merged_WB_PWT_DEMO.csv\", encoding=\"utf-8-sig\")\n",
    "df.columns = [c.lower().strip().replace(\" \", \"_\") for c in df.columns]\n",
    "df = df.replace('..', np.nan)\n",
    "wb_wide = df.pivot_table(\n",
    "    index=[\"country\", \"year\"],\n",
    "    columns=\"series_code\",\n",
    "    values=\"wb_value\",\n",
    "    aggfunc=\"first\"\n",
    ").reset_index()\n",
    "wb_rename = {\n",
    "    \"NY.GDP.PCAP.KD\": \"gdp_pc\",             \n",
    "    \"NE.TRD.GNFS.ZS\": \"trade_openness\",     \n",
    "    \"FP.CPI.TOTL.ZG\": \"inflation\",         \n",
    "    \"BX.KLT.DINV.WD.GD.ZS\": \"FDI\",         \n",
    "    \"NE.GDI.TOTL.ZS\": \"investment_ratio\"    \n",
    "}\n",
    "wb_wide = wb_wide.rename(columns={k: v for k, v in wb_rename.items() if k in wb_wide.columns})\n",
    "if \"gdp_pc\" in wb_wide.columns:\n",
    "    wb_wide[\"gdp_pc\"] = pd.to_numeric(wb_wide[\"gdp_pc\"], errors=\"coerce\")\n",
    "    wb_wide = wb_wide.sort_values([\"country\", \"year\"])\n",
    "    wb_wide[\"gdp_pc_growth\"] = (\n",
    "        wb_wide.groupby(\"country\")[\"gdp_pc\"].pct_change() * 100\n",
    "    )\n",
    "base_cols = [\n",
    "    \"country\", \"country_code\", \"series_name\", \"series_code\",\n",
    "    \"year\", \"wb_value\", \"countrycode\", \"currency_unit\",\n",
    "    \"demographic_indicator\", \"unnamed:_3\", \"unnamed:_4\",\n",
    "    \"unnamed:_5\", \"unnamed:_6\"\n",
    "]\n",
    "base_cols = [c for c in base_cols if c in df.columns]\n",
    "pwt_cols = [c for c in df.columns if c not in base_cols]\n",
    "pwt_panel = df.groupby([\"country\", \"year\"], as_index=False)[pwt_cols].first()\n",
    "if \"pop\" in pwt_panel.columns:\n",
    "    pwt_panel = pwt_panel.sort_values([\"country\", \"year\"])\n",
    "    pwt_panel[\"pop_growth\"] = (\n",
    "        pwt_panel.groupby(\"country\")[\"pop\"].pct_change() * 100\n",
    "    )\n",
    "if \"hc\" in pwt_panel.columns:\n",
    "    pwt_panel = pwt_panel.rename(columns={\"hc\": \"education\"})\n",
    "wgi = pd.read_excel(\"wgidataset.xlsx\")\n",
    "wgi.columns = [c.lower().strip() for c in wgi.columns]\n",
    "wgi = wgi.rename(columns={\"countryname\": \"country\"})\n",
    "wgi[\"estimate\"] = pd.to_numeric(wgi[\"estimate\"], errors=\"coerce\")\n",
    "wgi_pivot = wgi.pivot_table(\n",
    "    index=[\"country\", \"year\"],\n",
    "    columns=\"indicator\",\n",
    "    values=\"estimate\",\n",
    "    aggfunc=\"mean\"\n",
    ").reset_index()\n",
    "print(\"WGI columns:\", wgi_pivot.columns)\n",
    "panel = wb_wide.merge(pwt_panel, on=[\"country\", \"year\"], how=\"left\") \\\n",
    "               .merge(wgi_pivot, on=[\"country\", \"year\"], how=\"left\")\n",
    "print(panel.columns.tolist())\n",
    "print(panel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfe577d-9ece-4e57-b6e8-286399d502a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "va                float64\n",
      "pv                float64\n",
      "ge                float64\n",
      "rq                float64\n",
      "rl                float64\n",
      "cc                float64\n",
      "pop_growth        float64\n",
      "education         float64\n",
      "trade_openness    float64\n",
      "rgdpe             float64\n",
      "rgdpo             float64\n",
      "pop               float64\n",
      "dtype: object\n",
      "Any '..' left in X? -> False\n",
      "Highly correlated features to consider dropping: ['rq', 'rl', 'cc', 'rgdpo']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "target = \"gdp_pc_growth\"\n",
    "candidate_features = [\n",
    "    \"va\", \"pv\", \"ge\", \"rq\", \"rl\", \"cc\",\n",
    "    \"pop_growth\", \"education\",\n",
    "    \"trade_openness\", \"inflation\", \"FDI\", \"investment_ratio\",\n",
    "    \"rgdpe\", \"rgdpo\", \"pop\"\n",
    "]\n",
    "features = [f for f in candidate_features if f in panel.columns]\n",
    "#print(\"Using features:\", features)\n",
    "model_df = panel.dropna(subset=[target]).copy()\n",
    "model_df = model_df.replace('..', np.nan)\n",
    "for col in features + [target]:\n",
    "    model_df[col] = pd.to_numeric(model_df[col], errors='coerce')\n",
    "model_df = model_df.dropna(subset=features + [target])\n",
    "X = model_df[features]\n",
    "y = model_df[target]\n",
    "print(X.dtypes)\n",
    "\n",
    "print(\"Any '..' left in X? ->\", (X == '..').any().any())\n",
    "y_binned = pd.qcut(y, q=3, labels=['Low', 'Medium', 'High'])\n",
    "y_numeric = y_binned.map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "#turns our y variable into an integer value for low, medium, and high\n",
    "#goal is to have a classification model\n",
    "\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Upper triangle to avoid duplicate pairs\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find columns with correlation > 0.85\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.85)]\n",
    "print(\"Highly correlated features to consider dropping:\", to_drop)\n",
    "\n",
    "# Drop them from X\n",
    "X_reduced = X.drop(columns=to_drop)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_reduced, y_numeric, test_size=0.25, random_state=42\n",
    ")\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=.5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0c393c-3ca1-4beb-a247-96195f86fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best CV score: 0.5306850714658209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "param_grid = {\n",
    "    'n_estimators': [300,600,900],\n",
    "    'max_depth': [6,10,15],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07aef05-3371-40a4-a404-f808aa8a1dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.590027700831025\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       134\n",
      "           1       0.46      0.56      0.51       108\n",
      "           2       0.71      0.66      0.68       119\n",
      "\n",
      "    accuracy                           0.59       361\n",
      "   macro avg       0.60      0.59      0.59       361\n",
      "weighted avg       0.60      0.59      0.59       361\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73 47 14]\n",
      " [28 61 19]\n",
      " [16 24 79]]\n",
      "Test Accuracy: 0.5359116022099447\n",
      "Index(['va', 'pv', 'ge', 'pop_growth', 'education', 'trade_openness', 'rgdpe',\n",
      "       'pop'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#rf = RandomForestClassifier(max_depth = 12, min_samples_leaf =1, min_samples_split = 2, n_estimators = 200, random_state = 42)\n",
    "#rf.fit(X_train, y_train)\n",
    "y_pred_valid = grid.predict(X_valid)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_pred_valid))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_valid, y_pred_valid))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_valid))\n",
    "\n",
    "# Optional: evaluate on test set\n",
    "y_pred_test = grid.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(X_reduced.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ceb59-7731-4d99-9744-74440b31e1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
